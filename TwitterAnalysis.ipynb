{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "import string\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import Stream\n",
    "from pymongo import MongoClient\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully\n"
     ]
    }
   ],
   "source": [
    "C_KEY = 'kY96kGFsk7aKr7nOHoIZXF2Pj'\n",
    "C_SECRET = 'z8QasAyCPfAuP7yMY1RLQu1IPez5blCK8iFuU6ZHUfWM29X1Nj'\n",
    "A_TOKEN_KEY = '947092188-rewyA2gRgGBYih8YDrKUNAsTcCFznCNHAEWY2Xo2'\n",
    "A_TOKEN_SECRET = 'eEbuHDdkF88JJvmQ2smbtajyQjSzbfFj87Ls7Al5MuxZc'\n",
    "auth = tweepy.OAuthHandler(C_KEY, C_SECRET)\n",
    "auth.set_access_token(A_TOKEN_KEY, A_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "translator = str.maketrans('', '', string.punctuation+'‘“…')\n",
    "\n",
    "try:\n",
    "    connection = MongoClient('mongodb://cse472:cse472@162.243.41.219:27017/cse')\n",
    "    print(\"Connected successfully\")\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print(\"Connection faild: \" + e)\n",
    "    \n",
    "db = connection['cse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " tweets = db.training_tweets.find({\"class\": {\"$ne\" : \"\"}})\n",
    "alltweets = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    alltweets.append((tweet['text'], tweet['class']))\n",
    "    \n",
    "tweetswithsentiment = []\n",
    "allwordslist = []\n",
    "tweets = []\n",
    "masterlistoftweets = []\n",
    "for (tweet, positiveornegative) in alltweets:\n",
    "    longenoughwords = []\n",
    "    tweets.append(tweet)\n",
    "    words = [x.translate(translator).lower() for x in tweet.split()]\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) >= 3:\n",
    "            longenoughwords.append(word)\n",
    "            allwordslist.append(word)\n",
    "    masterlistoftweets.append(longenoughwords)\n",
    "    tweetswithsentiment.append((longenoughwords, positiveornegative))\n",
    "\n",
    "allwordslist = nltk.FreqDist(allwordslist)\n",
    "features = allwordslist.keys()\n",
    "\n",
    "def findfeatures(whatwords):\n",
    "    thesearethewords = set(whatwords)\n",
    "    featuresofwords = {}\n",
    "    for feature in features:\n",
    "        featuresofwords['contains(%s)' % feature] = (feature in thesearethewords)\n",
    "    return featuresofwords\n",
    "\n",
    "training_set = nltk.classify.apply_features(findfeatures, tweetswithsentiment)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testtweet = 'A top Obama official confirms that @realDonaldTrump was indeed the target of a government spying operation'\n",
    "# testtweet = [x.translate(translator).lower() for x in testtweet.split()]\n",
    "\n",
    "# print (classifier.classify(findfeatures(testtweet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyListener(StreamListener):\n",
    "    def __init__(self, time_limit=60):\n",
    "        self.start_time = time.time()\n",
    "        self.limit = time_limit\n",
    "        super(MyListener, self).__init__()\n",
    "        \n",
    "    def on_data(self, data):\n",
    "        if (time.time() - self.start_time) < self.limit:\n",
    "            data = json.loads(data)\n",
    "\n",
    "            if 'retweeted_status' in data and 'text' in data['retweeted_status']:\n",
    "                tweet = [x.translate(translator).lower() for x in data['retweeted_status']['text'].split()]\n",
    "                data['class'] = classifier.classify(findfeatures(tweet))\n",
    "                db.tweets.insert_one((data))\n",
    "            elif 'text' in data:\n",
    "                tweet = [x.translate(translator).lower() for x in data['text'].split()]\n",
    "                data['class'] = classifier.classify(findfeatures(tweet))\n",
    "                db.tweets.insert_one((data))\n",
    "                \n",
    "#                 if tweet_class == \"positive\":\n",
    "#                     print(data['text'])\n",
    "#                     return false\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myStream = Stream(auth, MyListener())\n",
    "myStream.filter(track=['trump', 'realDonaldTrump', 'POTUS'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
